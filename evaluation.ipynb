{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77731015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hendr\\Desktop\\3d-vae\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "from tqdm import tqdm\n",
    "import dask.config\n",
    "import xarray as xr\n",
    "import xbatcher as xb\n",
    "import numpy as np\n",
    "import dask\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "from data.era5 import gen_bgen\n",
    "from metrics.metrics import WeightedRMSE\n",
    "from models.latent_umbrella_net import LatentUmbrellaNet\n",
    "from models.autoencoder import Autoencoder\n",
    "\n",
    "NUM_WORKERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828eedc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hendr\\Desktop\\3d-vae\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: The loaded checkpoint was produced with Lightning v2.5.1, which is newer than your current Lightning version: v2.5.0.post0\n"
     ]
    }
   ],
   "source": [
    "def eval_lun_unet(\n",
    "    forecast_steps: int = 4, rounds: int = 1, save_to_csv: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    lun = LatentUmbrellaNet(\n",
    "        vae_ckpt_path=\"checkpoints/vae-kl-f8-rmse-disc-2-step=5000-z500=93.ckpt\",\n",
    "        vae_config_path=\"configs/autoencoder/kl-f8-disc.yaml\",\n",
    "        prediction_net_ckpt_path=\"checkpoints/prediction-model-val_loss=0.01241.ckpt\",\n",
    "        device=\"cuda\",\n",
    "        prediction_net_type=\"unet\",\n",
    "    )\n",
    "\n",
    "    dfs: list[pd.DataFrame] = []\n",
    "\n",
    "    for _ in range(rounds):\n",
    "        # create a thread pool for parallel processing\n",
    "        pool = ThreadPool(NUM_WORKERS)\n",
    "\n",
    "        # create a batch generator for the era5 data\n",
    "        bgen = gen_bgen(train=True)\n",
    "\n",
    "        # seed\n",
    "        s = random.randint(0, 1000)\n",
    "\n",
    "        indexes = np.arange(0, 6 * (forecast_steps + 2), 6) + s\n",
    "        indexes = indexes.tolist()\n",
    "\n",
    "        # load the data parallelly from the gsc\n",
    "        job = pool.map_async(bgen.__getitem__, indexes)\n",
    "        batches: list[xr.Dataset] = job.get()\n",
    "        pool.close()\n",
    "\n",
    "        # convert the batches to torch tensors\n",
    "        data = []\n",
    "        for batch in batches:\n",
    "            stacked = batch.to_stacked_array(\n",
    "                new_dim=\"channel\", sample_dims=[\"latitude\", \"longitude\"]\n",
    "            ).transpose(\"channel\", \"longitude\", \"latitude\")\n",
    "\n",
    "            item = torch.tensor(stacked.data)\n",
    "            item = item.unsqueeze(0)\n",
    "            item = item[:, :, :, :-1]\n",
    "\n",
    "            data.append(item)\n",
    "\n",
    "        data = torch.cat(data, dim=0)  # [x_0, x_6, x_12, x_18, x_24, x_30]\n",
    "\n",
    "        forecastst = []\n",
    "\n",
    "        for i in range(forecast_steps):\n",
    "            forecast = lun.forward(data[0].unsqueeze(0), data[1].unsqueeze(0), i + 1)\n",
    "            forecastst.append(forecast)\n",
    "\n",
    "        data = data[2:]  # [x_12, x_18, x_24, x_30]\n",
    "\n",
    "        forecastst = torch.cat(forecastst, dim=0)  # [y_12, y_18, y_24, y_30]\n",
    "\n",
    "        wrmse = WeightedRMSE(num_latitudes=720)\n",
    "\n",
    "        lun_unet = np.array(\n",
    "            [\n",
    "                wrmse(data[i].numpy(), forecastst[i].numpy())\n",
    "                for i in range(forecast_steps)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        lun_unet_dict = {\n",
    "            \"z500\": lun_unet[:, 50],\n",
    "            \"t850\": lun_unet[:, 14],\n",
    "            \"h700\": lun_unet[:, 65],\n",
    "            \"t2m\": lun_unet[:, 0],\n",
    "            \"u10\": lun_unet[:, 1],\n",
    "            \"u850\": lun_unet[:, 27],\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(lun_unet_dict)\n",
    "        dfs.append(df)\n",
    "\n",
    "    res_df = sum(dfs) / len(dfs)\n",
    "\n",
    "    if save_to_csv:\n",
    "        if not os.path.exists(\"./evaluation\"):\n",
    "            os.makedirs(\"./evaluation\")\n",
    "\n",
    "        res_df.to_csv(\"evaluation/lun_unet.csv\", index=False, header=True, mode=\"w\")\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "eval_lun_unet(\n",
    "    forecast_steps=2,\n",
    "    rounds=1,\n",
    "    save_to_csv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9187cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hendr\\Desktop\\3d-vae\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: The loaded checkpoint was produced with Lightning v2.5.1, which is newer than your current Lightning version: v2.5.0.post0\n"
     ]
    }
   ],
   "source": [
    "forecast_steps = 1\n",
    "\n",
    "lun = LatentUmbrellaNet(\n",
    "    vae_ckpt_path=\"checkpoints/vae-kl-f8-rmse-disc-2-step=5000-z500=93.ckpt\",\n",
    "    vae_config_path=\"configs/autoencoder/kl-f8-disc.yaml\",\n",
    "    prediction_net_ckpt_path=\"checkpoints/prediction-model-val_loss=0.01221.ckpt\",\n",
    "    device=\"cuda\",\n",
    "    prediction_net_type=\"unet\",\n",
    ")\n",
    "\n",
    "# create a thread pool for parallel processing\n",
    "pool = ThreadPool(NUM_WORKERS)\n",
    "\n",
    "# create a batch generator for the era5 data\n",
    "bgen = gen_bgen(train=True)\n",
    "\n",
    "# seed\n",
    "s = random.randint(0, 1000)\n",
    "\n",
    "indexes = np.arange(0, 6 * (forecast_steps + 2), 6) + s\n",
    "indexes = indexes.tolist()\n",
    "\n",
    "# load the data parallelly from the gsc\n",
    "job = pool.map_async(bgen.__getitem__, indexes)\n",
    "batches: list[xr.Dataset] = job.get()\n",
    "pool.close()\n",
    "\n",
    "# convert the batches to torch tensors\n",
    "data = []\n",
    "for batch in batches:\n",
    "    stacked = batch.to_stacked_array(\n",
    "        new_dim=\"channel\", sample_dims=[\"latitude\", \"longitude\"]\n",
    "    ).transpose(\"channel\", \"longitude\", \"latitude\")\n",
    "\n",
    "    item = torch.tensor(stacked.data)\n",
    "    item = item.unsqueeze(0)\n",
    "    item = item[:, :, :, :-1]\n",
    "\n",
    "    data.append(item)\n",
    "\n",
    "data = torch.cat(data, dim=0)  # [x_0, x_6, x_12, x_18, x_24, x_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95080e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 69, 1440, 720])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastst = []\n",
    "\n",
    "for i in range(forecast_steps):\n",
    "    forecast = lun.forward(data[0].unsqueeze(0), data[1].unsqueeze(0), i + 1)\n",
    "    forecastst.append(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd4d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[2:]  # [x_12, x_18, x_24, x_30]\n",
    "\n",
    "forecastst = torch.cat(forecastst, dim=0)  # [y_12, y_18, y_24, y_30]\n",
    "\n",
    "wrmse = WeightedRMSE(num_latitudes=720)\n",
    "\n",
    "lun_unet = np.array(\n",
    "    [wrmse(data[i].numpy(), forecastst[i].numpy()) for i in range(forecast_steps)]\n",
    ")\n",
    "\n",
    "lun_unet_dict = {\n",
    "    \"z500\": lun_unet[:, 50],\n",
    "    \"t850\": lun_unet[:, 14],\n",
    "    \"h700\": lun_unet[:, 65],\n",
    "    \"t2m\": lun_unet[:, 0],\n",
    "    \"u10\": lun_unet[:, 1],\n",
    "    \"u850\": lun_unet[:, 27],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(lun_unet_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
